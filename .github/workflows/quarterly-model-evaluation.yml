name: Quarterly Model Evaluation

on:
  schedule:
    # Run on 15th of Jan/Apr/Jul/Oct at 2 AM UTC
    - cron: '0 2 15 1,4,7,10 *'
  
  workflow_dispatch:
    inputs:
      test_model:
        description: 'Optional: Specific model to test (e.g., gpt-5.2)'
        required: false
        type: string
      skip_discovery:
        description: 'Skip discovery and just re-evaluate current models'
        required: false
        type: boolean
        default: false

jobs:
  evaluate-models:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    permissions:
      contents: write
      pull-requests: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python 3.14
        uses: actions/setup-python@v5
        with:
          python-version: '3.14'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create evaluation directory
        run: |
          QUARTER=$(date +%Y-Q$(( ($(date +%-m)-1)/3 + 1 )))
          mkdir -p data/quarterly-eval-${QUARTER}
          echo "EVAL_DIR=data/quarterly-eval-${QUARTER}" >> $GITHUB_ENV
          echo "QUARTER=${QUARTER}" >> $GITHUB_ENV
      
      - name: Discover new models
        if: ${{ !inputs.skip_discovery }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/discover_models.py \
            --output ${EVAL_DIR}/models-discovered.json \
            --probe-new \
            --capabilities-dir ${EVAL_DIR}/model-capabilities
      
      - name: Generate MODEL_CONFIGS for new models
        if: ${{ !inputs.skip_discovery }}
        run: |
          if [ -d "${EVAL_DIR}/model-capabilities" ]; then
            python scripts/generate_model_configs.py \
              --capabilities-dir ${EVAL_DIR}/model-capabilities \
              --output ${EVAL_DIR}/new-model-configs.py \
              --format both
            
            echo "NEW_MODELS_FOUND=true" >> $GITHUB_ENV
          else
            echo "NEW_MODELS_FOUND=false" >> $GITHUB_ENV
          fi
      
      - name: Quick comparison test
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          if [ -n "${{ inputs.test_model }}" ]; then
            MODELS="${{ inputs.test_model }} gpt-5.1 gpt-4o-mini"
          else
            MODELS="gpt-5.1 gpt-4o-mini gpt-5-mini"
          fi
          
          python scripts/compare_models.py \
            --models ${MODELS} \
            --iterations 10 \
            --parallel 30 \
            --output ${EVAL_DIR}/comparison-results.json
      
      - name: A/B configuration test
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/ab_test_models.py \
            --iterations 10 \
            --adaptive \
            --prune-after 3 \
            --keep-top 3 \
            --parallel 40 \
            --output ${EVAL_DIR}/ab-test-results.json
      
      - name: Complex article test
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/test_complex_article.py \
            --models gpt-5.1 gpt-4o-mini \
            --output ${EVAL_DIR}/complex-article-test.json
      
      - name: Analyze results and generate recommendation
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/analyze_evaluation.py \
            --eval-dir ${EVAL_DIR} \
            --output ${EVAL_DIR}/recommendation.md
      
      - name: Update config with recommendations
        run: |
          python scripts/update_config_from_eval.py \
            --eval-dir ${EVAL_DIR}
      
      - name: Commit evaluation results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add ${EVAL_DIR}/
          git commit -m "chore: quarterly model evaluation ${QUARTER}"
          git push origin HEAD:eval/${QUARTER}
      
      - name: Prepare PR body
        run: |
          cat ${EVAL_DIR}/recommendation.md > ${EVAL_DIR}/pr-body.md
          
          # Add new model configs if found
          if [ "${NEW_MODELS_FOUND}" = "true" ]; then
            echo "" >> ${EVAL_DIR}/pr-body.md
            echo "---" >> ${EVAL_DIR}/pr-body.md
            echo "" >> ${EVAL_DIR}/pr-body.md
            echo "## ðŸ†• New Models Detected" >> ${EVAL_DIR}/pr-body.md
            echo "" >> ${EVAL_DIR}/pr-body.md
            echo "New models were discovered and probed for capabilities." >> ${EVAL_DIR}/pr-body.md
            echo "See \`${EVAL_DIR}/new-model-configs.py\` for generated MODEL_CONFIGS." >> ${EVAL_DIR}/pr-body.md
            echo "" >> ${EVAL_DIR}/pr-body.md
            echo "**Action Required:** Review and integrate new model configurations into \`src/utils/openai_client.py\`" >> ${EVAL_DIR}/pr-body.md
          fi
      
      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          branch: eval/${{ env.QUARTER }}
          title: "ðŸ¤– Quarterly Model Evaluation - ${{ env.QUARTER }}"
          body-path: ${{ env.EVAL_DIR }}/pr-body.md
          labels: |
            automation
            model-evaluation
          assignees: ${{ github.repository_owner }}
